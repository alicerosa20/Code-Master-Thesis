{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ib54cjC0nmf"
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3993,
     "status": "ok",
     "timestamp": 1658145404120,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "shVYKQ8k0iUo"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tifffile import imread, imsave, imwrite\n",
    "import math\n",
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LeakyReLU, Conv3D, ZeroPadding3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tifffile import imread\n",
    "import math\n",
    "import xlwt\n",
    "from sys import stdout\n",
    "from xlwt import Workbook\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from torch.nn import ReflectionPad3d\n",
    "import torch\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCsfODtO0q2t",
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1658145404120,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "wtWqP5po0u4u"
   },
   "outputs": [],
   "source": [
    "def Generator(img_shape):\n",
    "    '''\n",
    "    Generator model\n",
    "    '''\n",
    "    def encoder_step(layer, Nf, ks, norm=True):\n",
    "        x = Conv3D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "        if norm:\n",
    "            x = InstanceNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def bottlenek(layer, Nf, ks):\n",
    "        x = Conv3D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        for i in range(4):\n",
    "            y = Conv3D(Nf, kernel_size=ks, strides=1, kernel_initializer='he_normal', padding='same')(x)\n",
    "            x = InstanceNormalization()(y)\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Concatenate()([x, y])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decoder_step(layer, layer_to_concatenate, Nf, ks):\n",
    "        x = Conv3DTranspose(Nf, kernel_size=ks, strides=2, padding='same', kernel_initializer='he_normal')(layer)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Concatenate()([x, layer_to_concatenate])\n",
    "        x = Dropout(0.2)(x)\n",
    "        return x\n",
    "\n",
    "    layers_to_concatenate = []\n",
    "    inputs = Input((64,64,64,2), name='input_image')\n",
    "    Nfilter_start = 64\n",
    "    depth = 4\n",
    "    ks = 4\n",
    "    x = inputs\n",
    "\n",
    "    # encoder\n",
    "    for d in range(depth-1):\n",
    "        if d==0:\n",
    "            x = encoder_step(x, Nfilter_start*np.power(2,d), ks, False)\n",
    "        else:\n",
    "            x = encoder_step(x, Nfilter_start*np.power(2,d), ks)\n",
    "        layers_to_concatenate.append(x)\n",
    "\n",
    "    # bottlenek\n",
    "    x = bottlenek(x, Nfilter_start*np.power(2,depth-1), ks)\n",
    "\n",
    "    # decoder\n",
    "    for d in range(depth-2, -1, -1): \n",
    "        x = decoder_step(x, layers_to_concatenate.pop(), Nfilter_start*np.power(2,d), ks)\n",
    "\n",
    "    # classifier\n",
    "    last = Conv3DTranspose(2, kernel_size=ks, strides=2, padding='same', kernel_initializer='he_normal', activation='sigmoid', name='output_generator')(x)\n",
    "   \n",
    "    return Model(inputs=inputs, outputs=last, name='Generator')\n",
    "\n",
    "def Discriminator(img_shape, mask_shape):\n",
    "    '''\n",
    "    Discriminator model\n",
    "    '''\n",
    "\n",
    "    inputs = Input(img_shape, name='input_image')\n",
    "    targets = Input(mask_shape, name='target_image')\n",
    "    Nfilter_start = 64\n",
    "    depth = 3\n",
    "    ks = 4\n",
    "\n",
    "    def encoder_step(layer, Nf, norm=True):\n",
    "        x = Conv3D(Nf, kernel_size=ks, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "        if norm:\n",
    "            x = InstanceNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    x = Concatenate()([inputs, targets])\n",
    "\n",
    "    for d in range(depth):\n",
    "        if d==0:\n",
    "            x = encoder_step(x, Nfilter_start*np.power(2,d), False)\n",
    "        else:\n",
    "            x = encoder_step(x, Nfilter_start*np.power(2,d))\n",
    "            \n",
    "    x = ZeroPadding3D()(x)\n",
    "    x = Conv3D(Nfilter_start*(2**depth), ks, strides=1, padding='valid', kernel_initializer='he_normal')(x) \n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "      \n",
    "    x = ZeroPadding3D()(x)\n",
    "    last = Conv3D(1, ks, strides=1, padding='valid', kernel_initializer='he_normal', name='output_discriminator')(x) \n",
    "\n",
    "    return Model(inputs=[inputs, targets], outputs=last, name='Discriminator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUvrmDb638W-",
    "tags": []
   },
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1658145404121,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "k9M_RzsQ3_rM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def diceLoss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, y_true.dtype)\n",
    "\n",
    "    num = tf.math.reduce_sum(tf.math.multiply(y_true, y_pred))\n",
    "    den = tf.math.reduce_sum(tf.math.add(y_true, y_pred))+1e-5\n",
    "\n",
    "    return 1-2*num/den\n",
    "\n",
    "def weighted_diceLoss(y_true,y_pred, class_weight=[6.63,0.5]):\n",
    "    \n",
    "    weighted_loss = class_weight[0]*diceLoss(y_true[:,:,:,:,0], y_pred[:,:,:,:,0])+class_weight[1]*diceLoss(y_true[:,:,:,:,1], y_pred[:,:,:,:,1])\n",
    "    loss = weighted_loss/np.sum(class_weight)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_fake_output):\n",
    "    real_loss = tf.math.reduce_mean(tf.math.pow(tf.ones_like(disc_real_output) - disc_real_output, 2))\n",
    "    fake_loss = tf.math.reduce_mean(tf.math.pow(tf.zeros_like(disc_fake_output) - disc_fake_output, 2))\n",
    "\n",
    "    disc_loss = 0.5*(real_loss + fake_loss)\n",
    "\n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "def generator_loss(target, gen_output, disc_fake_output, alpha):\n",
    "    \n",
    "    # generalized dice loss\n",
    "    dice_loss = diceLoss(target, gen_output)\n",
    "    \n",
    "    # disc loss\n",
    "    disc_loss = tf.math.reduce_mean(tf.math.pow(tf.ones_like(disc_fake_output) - disc_fake_output, 2))\n",
    "       \n",
    "    # total loss\n",
    "    gen_loss = alpha*dice_loss + disc_loss\n",
    "\n",
    "    return gen_loss, dice_loss, disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvR5EPUL4RMs",
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2607,
     "status": "ok",
     "timestamp": 1658145406719,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "Pdal82yN4Tsx"
   },
   "outputs": [],
   "source": [
    "# Models \n",
    "img_shape = (64,64,64,2)\n",
    "mask_shape = (64,64,64,2)\n",
    "\n",
    "G = Generator(img_shape)\n",
    "D = Discriminator(img_shape, mask_shape)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "\n",
    "def train_step(image, target, alpha):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "            gen_output = G(image, training=True)\n",
    "\n",
    "            disc_real_output = D([image, target], training=True)\n",
    "            disc_fake_output = D([image, gen_output], training=True)\n",
    "            disc_loss = discriminator_loss(disc_real_output, disc_fake_output)\n",
    "            \n",
    "            gen_loss, dice_loss, disc_loss_gen = generator_loss(target, gen_output, disc_fake_output, alpha)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, G.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, D.trainable_variables))\n",
    "        \n",
    "    return gen_loss, dice_loss, disc_loss_gen\n",
    "\n",
    "\n",
    "def test_step(image, target, alpha):\n",
    "    gen_output = G(image, training=False)\n",
    "\n",
    "    disc_real_output = D([image, target], training=False)\n",
    "    disc_fake_output = D([image, gen_output], training=False)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_fake_output)\n",
    "\n",
    "    gen_loss, dice_loss, disc_loss_gen = generator_loss(target, gen_output, disc_fake_output, alpha)\n",
    "        \n",
    "    return gen_loss, dice_loss, disc_loss_gen\n",
    "\n",
    "\n",
    "def thresholding(patch_prediction):\n",
    "    patch_ind_nuclei = np.argwhere(patch_prediction[:,:,:,0] > 0.5)\n",
    "    patch_ind_golgi = np.argwhere(patch_prediction[:,:,:,1] > 0.5)\n",
    "\n",
    "    patch_prediction_thr = np.zeros((patch_prediction.shape[0],patch_prediction.shape[1],patch_prediction.shape[2],3))\n",
    "\n",
    "    for i in range(patch_ind_nuclei.shape[0]):\n",
    "      patch_prediction_thr[patch_ind_nuclei[i,0],patch_ind_nuclei[i,1],patch_ind_nuclei[i,2],0]=1 \n",
    "\n",
    "    for j in range(patch_ind_golgi.shape[0]):\n",
    "      patch_prediction_thr[patch_ind_golgi[j,0],patch_ind_golgi[j,1],patch_ind_golgi[j,2],1]=1\n",
    "\n",
    "    return patch_prediction_thr \n",
    "\n",
    "\n",
    "def fit(train_gen, valid_gen, alpha, epochs):\n",
    "\n",
    "  path = './Dataset/Results_Pix2Pix'\n",
    "  if os.path.exists(path)==False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "  \n",
    "  Nt = len(train_gen)\n",
    "  history = {'train': [], 'valid': []}\n",
    "  prev_loss = np.inf\n",
    "  n = 0\n",
    "    \n",
    "  epoch_v2v_loss = tf.keras.metrics.Mean()\n",
    "  epoch_dice_loss = tf.keras.metrics.Mean()\n",
    "  epoch_disc_loss = tf.keras.metrics.Mean()\n",
    "  epoch_v2v_loss_val = tf.keras.metrics.Mean()\n",
    "  epoch_dice_loss_val = tf.keras.metrics.Mean()\n",
    "  epoch_disc_loss_val = tf.keras.metrics.Mean()\n",
    "\n",
    "  for e in range(epochs):\n",
    "    print('Epoch {}/{}'.format(e+1,epochs))\n",
    "    b = 0\n",
    "    \n",
    "    for Xb, yb in train_gen:\n",
    "        b += 1\n",
    "\n",
    "        losses = train_step(Xb, yb[:,:,:,:,:2], alpha)\n",
    "        epoch_v2v_loss.update_state(losses[0])\n",
    "        epoch_dice_loss.update_state(losses[1])\n",
    "        epoch_disc_loss.update_state(losses[2])\n",
    "        \n",
    "        stdout.write('\\rBatch: {}/{} - loss: {:.4f} - dice_loss: {:.4f} - disc_loss: {:.4f}'\n",
    "                      .format(b, Nt, epoch_v2v_loss.result(), epoch_dice_loss.result(), epoch_disc_loss.result()))\n",
    "        stdout.flush()\n",
    "    history['train'].append([epoch_v2v_loss.result(), epoch_dice_loss.result(), epoch_disc_loss.result()])\n",
    "    \n",
    "    for Xb, yb in valid_gen:\n",
    "        losses_val = test_step(Xb, yb[:,:,:,:,:2], alpha)\n",
    "        epoch_v2v_loss_val.update_state(losses_val[0])\n",
    "        epoch_dice_loss_val.update_state(losses_val[1])\n",
    "        epoch_disc_loss_val.update_state(losses_val[2])\n",
    "            \n",
    "    stdout.write('\\n               loss_val: {:.4f} - dice_loss_val: {:.4f} - disc_loss_val: {:.4f}'\n",
    "                  .format(epoch_v2v_loss_val.result(), epoch_dice_loss_val.result(), epoch_disc_loss_val.result()))\n",
    "    stdout.flush()\n",
    "    history['valid'].append([epoch_v2v_loss_val.result(), epoch_dice_loss_val.result(), epoch_disc_loss_val.result()])\n",
    "    \n",
    "    # save pred image at epoch e\n",
    "    #y_pred = G.predict(Xb)\n",
    "    #pred_patch = y_pred[0,:,:,:,:]\n",
    "    #pred_patch_thr = thresholding(pred_patch)\n",
    "\n",
    "    #predicted_mask = pred_patch_thr*255.0\n",
    "    #predicted_mask = predicted_mask.astype('uint8')\n",
    "\n",
    "    #imwrite(path + '/pred_mask_' + str(e+1) , predicted_mask, photometric='rgb')\n",
    "\n",
    "    # save models \n",
    "    path_models = './Models_Pix2Pix'\n",
    "    if os.path.exists(path_models)==False:\n",
    "      os.mkdir(path_models)\n",
    "\n",
    "    print(' ')\n",
    "    if epoch_v2v_loss_val.result() < prev_loss:    \n",
    "        G.save_weights(path_models + '/Generator.h5') \n",
    "        D.save_weights(path_models + '/Discriminator.h5')\n",
    "        print(\"Validation loss decresaed from {:.4f} to {:.4f}. Models' weights are now saved.\".format(prev_loss, epoch_v2v_loss_val.result()))\n",
    "        prev_loss = epoch_v2v_loss_val.result()\n",
    "        n = 0\n",
    "    else:\n",
    "        print(\"Validation loss did not decrese from {:.4f}.\".format(prev_loss))\n",
    "        # Early Stopping\n",
    "        n = n+1\n",
    "        if n > 20:\n",
    "            return history\n",
    "    print(' ')\n",
    "\n",
    "    # resets losses states\n",
    "    epoch_v2v_loss.reset_states()\n",
    "    epoch_dice_loss.reset_states()\n",
    "    epoch_disc_loss.reset_states()\n",
    "    epoch_v2v_loss_val.reset_states()\n",
    "    epoch_dice_loss_val.reset_states()\n",
    "    epoch_disc_loss_val.reset_states()\n",
    "    \n",
    "    del Xb, yb\n",
    "        \n",
    "  return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVFlG5TVDlYy",
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1658145444537,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "SJqkDbvHTLWs"
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1658145445411,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "xKjwBmuCEGD_"
   },
   "outputs": [],
   "source": [
    "import data_generator\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "npm90hJQDk_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 17:15:09.150553: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-10-23 17:15:09.303204: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-23 17:15:09.303568: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-23 17:15:09.303588: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-10-23 17:15:09.303992: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-23 17:15:09.304045: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73/73 - loss: 8.2937 - dice_loss: 0.9367 - disc_loss: 3.610422\n",
      "               loss_val: 4.5996 - dice_loss_val: 0.8465 - disc_loss_val: 0.3669 \n",
      "Validation loss decresaed from inf to 4.5996. Models' weights are now saved.\n",
      " \n",
      "Epoch 2/200\n",
      "Batch: 73/73 - loss: 3.6775 - dice_loss: 0.5891 - disc_loss: 0.7320\n",
      "               loss_val: 3.1427 - dice_loss_val: 0.3621 - disc_loss_val: 1.3323 \n",
      "Validation loss decresaed from 4.5996 to 3.1427. Models' weights are now saved.\n",
      " \n",
      "Epoch 3/200\n",
      "Batch: 73/73 - loss: 2.1054 - dice_loss: 0.3264 - disc_loss: 0.4734\n",
      "               loss_val: 1.9387 - dice_loss_val: 0.2834 - disc_loss_val: 0.5216 \n",
      "Validation loss decresaed from 3.1427 to 1.9387. Models' weights are now saved.\n",
      " \n",
      "Epoch 4/200\n",
      "Batch: 73/73 - loss: 1.7511 - dice_loss: 0.2687 - disc_loss: 0.4074\n",
      "               loss_val: 1.3810 - dice_loss_val: 0.2504 - disc_loss_val: 0.1290 \n",
      "Validation loss decresaed from 1.9387 to 1.3810. Models' weights are now saved.\n",
      " \n",
      "Epoch 5/200\n",
      "Batch: 73/73 - loss: 1.5816 - dice_loss: 0.2429 - disc_loss: 0.3671\n",
      "               loss_val: 1.3141 - dice_loss_val: 0.2252 - disc_loss_val: 0.1880 \n",
      "Validation loss decresaed from 1.3810 to 1.3141. Models' weights are now saved.\n",
      " \n",
      "Epoch 6/200\n",
      "Batch: 73/73 - loss: 1.4934 - dice_loss: 0.2305 - disc_loss: 0.3411\n",
      "               loss_val: 1.3182 - dice_loss_val: 0.2234 - disc_loss_val: 0.2014 \n",
      "Validation loss did not decrese from 1.3141.\n",
      " \n",
      "Epoch 7/200\n",
      "Batch: 73/73 - loss: 1.4595 - dice_loss: 0.2222 - disc_loss: 0.3484\n",
      "               loss_val: 1.3206 - dice_loss_val: 0.2179 - disc_loss_val: 0.2311 \n",
      "Validation loss did not decrese from 1.3141.\n",
      " \n",
      "Epoch 8/200\n",
      "Batch: 73/73 - loss: 1.3829 - dice_loss: 0.2190 - disc_loss: 0.2882\n",
      "               loss_val: 1.2846 - dice_loss_val: 0.2177 - disc_loss_val: 0.1959 \n",
      "Validation loss decresaed from 1.3141 to 1.2846. Models' weights are now saved.\n",
      " \n",
      "Epoch 9/200\n",
      "Batch: 73/73 - loss: 1.3796 - dice_loss: 0.2162 - disc_loss: 0.2987\n",
      "               loss_val: 1.2395 - dice_loss_val: 0.2130 - disc_loss_val: 0.1744 \n",
      "Validation loss decresaed from 1.2846 to 1.2395. Models' weights are now saved.\n",
      " \n",
      "Epoch 10/200\n",
      "Batch: 73/73 - loss: 1.3738 - dice_loss: 0.2136 - disc_loss: 0.3057\n",
      "               loss_val: 1.2589 - dice_loss_val: 0.2127 - disc_loss_val: 0.1954 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 11/200\n",
      "Batch: 73/73 - loss: 1.3599 - dice_loss: 0.2108 - disc_loss: 0.3061\n",
      "               loss_val: 1.2587 - dice_loss_val: 0.2099 - disc_loss_val: 0.2094 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 12/200\n",
      "Batch: 73/73 - loss: 1.3635 - dice_loss: 0.2111 - disc_loss: 0.3079\n",
      "               loss_val: 1.2711 - dice_loss_val: 0.2093 - disc_loss_val: 0.2245 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 13/200\n",
      "Batch: 73/73 - loss: 1.3582 - dice_loss: 0.2097 - disc_loss: 0.3096\n",
      "               loss_val: 1.2710 - dice_loss_val: 0.2077 - disc_loss_val: 0.2327 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 14/200\n",
      "Batch: 73/73 - loss: 1.3556 - dice_loss: 0.2078 - disc_loss: 0.3164\n",
      "               loss_val: 1.3409 - dice_loss_val: 0.2101 - disc_loss_val: 0.2906 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 15/200\n",
      "Batch: 73/73 - loss: 1.3422 - dice_loss: 0.2067 - disc_loss: 0.3087\n",
      "               loss_val: 1.3150 - dice_loss_val: 0.2091 - disc_loss_val: 0.2695 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 16/200\n",
      "Batch: 73/73 - loss: 1.3531 - dice_loss: 0.2062 - disc_loss: 0.3219\n",
      "               loss_val: 1.3196 - dice_loss_val: 0.2057 - disc_loss_val: 0.2910 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 17/200\n",
      "Batch: 73/73 - loss: 1.3591 - dice_loss: 0.2055 - disc_loss: 0.3316\n",
      "               loss_val: 1.3159 - dice_loss_val: 0.2092 - disc_loss_val: 0.2699 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 18/200\n",
      "Batch: 73/73 - loss: 1.3955 - dice_loss: 0.2082 - disc_loss: 0.3542\n",
      "               loss_val: 1.3520 - dice_loss_val: 0.2071 - disc_loss_val: 0.3167 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 19/200\n",
      "Batch: 73/73 - loss: 1.3650 - dice_loss: 0.2046 - disc_loss: 0.3420\n",
      "               loss_val: 1.3318 - dice_loss_val: 0.2088 - disc_loss_val: 0.2879 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 20/200\n",
      "Batch: 73/73 - loss: 1.3853 - dice_loss: 0.2069 - disc_loss: 0.3506\n",
      "               loss_val: 1.3243 - dice_loss_val: 0.2069 - disc_loss_val: 0.2900 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 21/200\n",
      "Batch: 73/73 - loss: 1.3788 - dice_loss: 0.2060 - disc_loss: 0.3489\n",
      "               loss_val: 1.3360 - dice_loss_val: 0.2071 - disc_loss_val: 0.3003 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 22/200\n",
      "Batch: 73/73 - loss: 1.3723 - dice_loss: 0.2048 - disc_loss: 0.3485\n",
      "               loss_val: 1.3213 - dice_loss_val: 0.2047 - disc_loss_val: 0.2976 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 23/200\n",
      "Batch: 73/73 - loss: 1.3579 - dice_loss: 0.2027 - disc_loss: 0.3445\n",
      "               loss_val: 1.3321 - dice_loss_val: 0.2051 - disc_loss_val: 0.3065 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 24/200\n",
      "Batch: 73/73 - loss: 1.3485 - dice_loss: 0.2008 - disc_loss: 0.3446\n",
      "               loss_val: 1.3169 - dice_loss_val: 0.2075 - disc_loss_val: 0.2793 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 25/200\n",
      "Batch: 73/73 - loss: 1.3135 - dice_loss: 0.1960 - disc_loss: 0.3333\n",
      "               loss_val: 1.3274 - dice_loss_val: 0.2087 - disc_loss_val: 0.2842 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 26/200\n",
      "Batch: 73/73 - loss: 1.3075 - dice_loss: 0.1956 - disc_loss: 0.3295\n",
      "               loss_val: 1.3170 - dice_loss_val: 0.2062 - disc_loss_val: 0.2859 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 27/200\n",
      "Batch: 73/73 - loss: 1.3140 - dice_loss: 0.1964 - disc_loss: 0.3322\n",
      "               loss_val: 1.3146 - dice_loss_val: 0.2042 - disc_loss_val: 0.2934 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 28/200\n",
      "Batch: 73/73 - loss: 1.3459 - dice_loss: 0.2006 - disc_loss: 0.3430\n",
      "               loss_val: 1.3334 - dice_loss_val: 0.2081 - disc_loss_val: 0.2931 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 29/200\n",
      "Batch: 73/73 - loss: 1.2923 - dice_loss: 0.1945 - disc_loss: 0.3200\n",
      "               loss_val: 1.3311 - dice_loss_val: 0.2044 - disc_loss_val: 0.3091 \n",
      "Validation loss did not decrese from 1.2395.\n",
      " \n",
      "Epoch 30/200\n",
      "Batch: 73/73 - loss: 1.3339 - dice_loss: 0.1991 - disc_loss: 0.3384\n",
      "               loss_val: 1.3453 - dice_loss_val: 0.2068 - disc_loss_val: 0.3114 \n",
      "Validation loss did not decrese from 1.2395.\n"
     ]
    }
   ],
   "source": [
    "alpha=5\n",
    "n_epochs = 200\n",
    "batch_size = 4\n",
    "\n",
    "traingen = DataGenerator('Train', batch_size=batch_size, img_size=(64,64,64,2), mask_size=(64,64,64,2))\n",
    "\n",
    "valgen = DataGenerator('Validation', batch_size=batch_size, img_size=(64,64,64,2), mask_size=(64,64,64,2))\n",
    "\n",
    "# train the vox2vox model\n",
    "h = fit(traingen, valgen, alpha, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOhnNabGSjOU"
   },
   "outputs": [],
   "source": [
    "def model_plots(history, plot_dir):\n",
    "  #plot the training and validation IoU and loss at each epoch\n",
    "    loss = np.array(history['train'][:])[:,1]\n",
    "    val_loss = np.array(history['valid'][:])[:,1]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(plot_dir + '/loss_plot.png')\n",
    "    plt.clf()\n",
    "\n",
    "  #acc = history.history['dice_coefficient']\n",
    "  #val_acc = history.history['val_dice_coefficient']\n",
    "\n",
    "  #plt.plot(epochs, acc, 'y', label='Training Dice')\n",
    "  #plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
    "  #plt.title('Training and validation Dice')\n",
    "  #plt.xlabel('Epochs')\n",
    "  #plt.ylabel('Dice')\n",
    "  #plt.legend()\n",
    "  #plt.savefig(plot_dir + '/dice_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wI8ZSd1wSjOV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dir = './Dataset/Model_Plots_Pix2Pix'\n",
    "if os.path.exists(plot_dir)==False:\n",
    "    os.mkdir(plot_dir)\n",
    "\n",
    "model_plots(h, plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0l9Y_XNSjOW",
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ryDH6VEVSjOW"
   },
   "outputs": [],
   "source": [
    "def padding(image,size):\n",
    "\n",
    "    img_reshape = np.moveaxis(image, -1, 0)\n",
    "    \n",
    "    m = ReflectionPad3d((0,size[2]-image.shape[2],0,size[1]-image.shape[1],0,size[0]-image.shape[0]))\n",
    "    input = torch.tensor(img_reshape, dtype=torch.float)\n",
    "    output = m(input)\n",
    "    pad_img = output.numpy()\n",
    "    pad_img = np.moveaxis(pad_img, 0, -1)\n",
    "    \n",
    "    return pad_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6v7kIgY8SjOX"
   },
   "outputs": [],
   "source": [
    "def thresholding(patch_prediction):\n",
    "  patch_ind_nuclei = np.argwhere(patch_prediction[:,:,:,0] > 0.5)\n",
    "  patch_ind_golgi = np.argwhere(patch_prediction[:,:,:,1] > 0.5)\n",
    "\n",
    "  patch_prediction_thr = np.zeros((patch_prediction.shape[0],patch_prediction.shape[1],patch_prediction.shape[2],3))\n",
    "\n",
    "  for i in range(patch_ind_nuclei.shape[0]):\n",
    "    patch_prediction_thr[patch_ind_nuclei[i,0],patch_ind_nuclei[i,1],patch_ind_nuclei[i,2],0]=1 \n",
    "\n",
    "  for j in range(patch_ind_golgi.shape[0]):\n",
    "    patch_prediction_thr[patch_ind_golgi[j,0],patch_ind_golgi[j,1],patch_ind_golgi[j,2],1]=1\n",
    "    \n",
    "  return patch_prediction_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cWKNfGvqSjOX"
   },
   "outputs": [],
   "source": [
    "def pred_mask(image, mask_shape):\n",
    "  patch_size = 64\n",
    "  step = 48\n",
    "\n",
    "  pred_mask = np.zeros(((image.shape[0] // step)*step + patch_size,(image.shape[1] // step)*step + patch_size,64,3))\n",
    "  _image = padding(image, ((image.shape[0] // step)*step + patch_size,(image.shape[1] // step)*step + patch_size,64,3))\n",
    "\n",
    "  i = 0\n",
    "  while i + patch_size <= _image.shape[0]:\n",
    "    j = 0\n",
    "    while j + patch_size <= _image.shape[1]:\n",
    "\n",
    "        tst_patch = _image[i:i+patch_size, j:j+patch_size, :, :]\n",
    "        tst_patch = np.array([tst_patch / 255.])\n",
    "        preds_tst = G(tst_patch, training=False)\n",
    "        pred_patch = preds_tst[0,:,:,:,:]\n",
    "        pred_patch_thr = thresholding(pred_patch)\n",
    "\n",
    "        pred_mask[i:i+patch_size, j:j+patch_size,:,0] = np.array(np.logical_or(pred_mask[i:i+patch_size, j:j+patch_size, :,0], pred_patch_thr[:,:,:,0], dtype = 'float64'))\n",
    "        pred_mask[i:i+patch_size, j:j+patch_size,:,1] = np.array(np.logical_or(pred_mask[i:i+patch_size, j:j+patch_size, :,1], pred_patch_thr[:,:,:,1], dtype = 'float64'))\n",
    "        pred_mask[i:i+patch_size, j:j+patch_size,:,2] = 0\n",
    "\n",
    "        j += step\n",
    "        \n",
    "    i += step\n",
    "    \n",
    "  _pred_mask = np.zeros(mask_shape)\n",
    "  _pred_mask = pred_mask[0:mask_shape[0],0:mask_shape[1],0:mask_shape[2],:]\n",
    "\n",
    "  return _pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JJVNFuHESjOY"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smoothing_factor = 1\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return(K.sum(flat_y_true * flat_y_pred) / K.sum(flat_y_pred) )\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return(K.sum(flat_y_true * flat_y_pred) / K.sum(flat_y_true) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "g6xzOEs4SjOY"
   },
   "outputs": [],
   "source": [
    "def metrics(mask, _pred_mask):\n",
    "  _mask = mask/255.\n",
    "\n",
    "  dice_coef_nuclei = dice_coefficient(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "  dice_coef_golgi = dice_coefficient(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "  prec_nuclei = precision(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "  prec_golgi = precision(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "  recall_nuclei = recall(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "  recall_golgi = recall(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "\n",
    "  return [round(dice_coef_nuclei.numpy(),4), round(dice_coef_golgi.numpy(),4), \n",
    "          round(prec_nuclei.numpy(),4), round(prec_golgi.numpy(),4), round(recall_nuclei.numpy(),4),\n",
    "          round(recall_golgi.numpy(),4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qopqvtRzSjOZ"
   },
   "outputs": [],
   "source": [
    "def write_to_excel(wb,sheet_name,metrics, result_dir):\n",
    "\n",
    "  # add_sheet is used to create sheet.\n",
    "  sheet1 = wb.add_sheet(sheet_name)\n",
    "\n",
    "  sheet1.write(0, 0, 'Dice Coeffient Nuclei')\n",
    "  sheet1.write(0, 1, 'Dice Coeffient Golgi')\n",
    "  sheet1.write(0, 2, 'Precision Nuclei')\n",
    "  sheet1.write(0, 3, 'Precision Golgi')\n",
    "  sheet1.write(0, 4, 'Recall Nuclei')\n",
    "  sheet1.write(0, 5, 'Recall Golgi')\n",
    "  sheet1.write(1, 0, metrics[0])\n",
    "  sheet1.write(1, 1, metrics[1])\n",
    "  sheet1.write(1, 2, metrics[2])\n",
    "  sheet1.write(1, 3, metrics[3])\n",
    "  sheet1.write(1, 4, metrics[4])\n",
    "  sheet1.write(1, 5, metrics[5])\n",
    "\n",
    "  wb.save(result_dir + '/results_metrics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LsKxziyzSjOZ"
   },
   "outputs": [],
   "source": [
    "def test_model(base_dir):\n",
    "\n",
    "  fnames = os.listdir(base_dir + 'Images/')\n",
    "\n",
    "  # Workbook is created\n",
    "  wb = Workbook()\n",
    "\n",
    "  result_dir = './Dataset/Results_Pix2Pix'\n",
    "  if os.path.exists(result_dir)==False:\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "  for i in range(len(fnames)):\n",
    "\n",
    "    image = imread(base_dir + 'Images/' + fnames[i])[:,:,:,:2]\n",
    "    mask = imread(base_dir + 'Masks/' + fnames[i])\n",
    "\n",
    "    predicted_mask = pred_mask(image, image.shape)\n",
    "\n",
    "    _predicted_mask = predicted_mask*255.0\n",
    "    _predicted_mask = _predicted_mask.astype('uint8')\n",
    "\n",
    "    imwrite(result_dir + '/pred_mask_' + fnames[i] , _predicted_mask, photometric='rgb')\n",
    "\n",
    "    _metrics = metrics(mask, predicted_mask)\n",
    "\n",
    "    write_to_excel(wb,'Sheet_' + fnames[i].split('.')[0], _metrics, result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44702,
     "status": "ok",
     "timestamp": 1658139209619,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "WURo2qAsSjOa",
    "outputId": "821ab121-2e45-42f9-de4b-65c34d21dbbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.63827729225159 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Load the pretrained model for testing and predictions. \n",
    "\n",
    "img_shape=(64,64,64,2)\n",
    "G = Generator(img_shape)\n",
    "G.load_weights('./Models_Pix2Pix/Generator.h5')\n",
    "\n",
    "base_dir = './Dataset/Patches_Pre_64/Test/'\n",
    "test_model(base_dir)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbaVGWKy6Eu4",
    "tags": []
   },
   "source": [
    "# Gerar mascaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1658142472974,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "KpjbK92v1d_j"
   },
   "outputs": [],
   "source": [
    "def generate_synthetic_masks(train_dir_img, train_dir_mask, n_patches):\n",
    "\n",
    "  size_img = (128,128,64,3)\n",
    "  size_mask = (128,128,64,2)\n",
    "\n",
    "  for p in range(n_patches):\n",
    "      img = np.zeros(size_img)\n",
    "      img[:,:,:,0] = np.random.uniform(low=10, high=20, size=(128,128,64))\n",
    "      img[:,:,:,1] = np.random.uniform(low=5, high=15, size=(128,128,64))\n",
    "      img = img/255.\n",
    "      imwrite(train_dir_img + '/img_patch_' + str(5) + str(p) + '.tif', img)\n",
    "\n",
    "  for k in range(n_patches):\n",
    "      patch = np.zeros(size_mask)\n",
    "      patch = patch/255.\n",
    "      imwrite(train_dir_mask + '/img_patch_' + str(5) + str(k) + '.tif', patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 14319,
     "status": "ok",
     "timestamp": 1658142488366,
     "user": {
      "displayName": "Alice Rosa",
      "userId": "08910053332263565279"
     },
     "user_tz": -60
    },
    "id": "XswuE6Z3-0f5"
   },
   "outputs": [],
   "source": [
    "generate_synthetic_masks('./Dataset/Patches_128/Train/Images', './Dataset/Patches_128/Train/Masks', 12)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5Ib54cjC0nmf"
   ],
   "name": "3D-Pix2Pix-V3.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
