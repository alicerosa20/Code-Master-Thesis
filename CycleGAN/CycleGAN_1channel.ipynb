{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anSn07EhuGES",
    "tags": []
   },
   "source": [
    "# Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2758,
     "status": "ok",
     "timestamp": 1655719006528,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "Kb0w8OA2tzMj"
   },
   "outputs": [],
   "source": [
    "# example of training a cyclegan on the horse2zebra dataset\n",
    "from random import random\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv3D, BatchNormalization\n",
    "from keras.layers import Conv3DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import UpSampling3D\n",
    "from keras.activations import sigmoid\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from tifffile import imread, imsave, imwrite\n",
    "from sys import stdout\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from keras import backend as K\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "from torch.nn import ReflectionPad3d\n",
    "import torch\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_TQLQxzuJIz",
    "tags": []
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SW_t-_lNt2jy"
   },
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "\n",
    "    # C64\n",
    "    d = Conv3D(64, 4, strides=2, padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv3D(128, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv3D(256, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv3D(512, 4, strides=2, padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv3D(512, 4, padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    patch_out = Conv3D(1, 4, padding='same', kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001, beta_1=0.5), loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9ylsvemot8OV"
   },
   "outputs": [],
   "source": [
    "# generator a resnet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # first layer convolutional layer\n",
    "    g = Conv3D(n_filters, 3, padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # second convolutional layer\n",
    "    g = Conv3D(n_filters, 3, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    # concatenate merge channel-wise with input layer\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape, n_resnet=9):\n",
    "\n",
    "\t# weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # c7s1-32\n",
    "    g = Conv3D(16, 7, padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d64\n",
    "    g = Conv3D(32, 3, strides=2, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d128\n",
    "    g = Conv3D(64, 3, strides=2, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(64, g)\n",
    "    # u64\n",
    "    g = Conv3DTranspose(32, 3, strides=2, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # u32\n",
    "    g = Conv3DTranspose(16, 3, strides=2, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # c7s1-2\n",
    "    g = Conv3D(1, 7, padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization()(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6oZZS6Gbt_hX"
   },
   "outputs": [],
   "source": [
    "# define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "\t# ensure the model we're updating is trainable\n",
    "\tg_model_1.trainable = True\n",
    "\t# mark discriminator as not trainable\n",
    "\td_model.trainable = False\n",
    "\t# mark other generator model as not trainable\n",
    "\tg_model_2.trainable = False\n",
    "\t# discriminator element\n",
    "\tinput_gen = Input(shape=image_shape)\n",
    "\tgen1_out = g_model_1(input_gen)\n",
    "\toutput_d = d_model(gen1_out)\n",
    "\t# identity element\n",
    "\tinput_id = Input(shape=image_shape)\n",
    "\toutput_id = g_model_1(input_id)\n",
    "\t# forward cycle\n",
    "\toutput_f = g_model_2(gen1_out)\n",
    "\t# backward cycle\n",
    "\tgen2_out = g_model_2(input_id)\n",
    "\toutput_b = g_model_1(gen2_out)\n",
    "\t# define model graph\n",
    "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "\t# define optimization algorithm configuration\n",
    "\topt = Adam(learning_rate=0.0005, beta_1=0.5)\n",
    "\t# compile model with weighting of least squares loss and L1 loss\n",
    "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 30, 30], optimizer=opt)\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcZ9nLp6uMAQ",
    "tags": []
   },
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UoX78GBw46io"
   },
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(dataset, ID, filename, dim):\n",
    "    # load the dataset\n",
    "    if dataset == '/Images/':\n",
    "        dim = (128,128,64,3)\n",
    "    elif dataset == '/Masks/':\n",
    "        dim = (128,128,64,2)\n",
    "        \n",
    "    X = np.empty((len(ID), *dim))\n",
    "\n",
    "    for i, ID_path in enumerate(ID):\n",
    "        X[i,] = imread(filename + dataset + ID_path)\n",
    "        X[i,] = (X[i,] - 0.5) / 0.5\n",
    "    \n",
    "    return X[:,:,:,:,0]\n",
    "\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_size, filename, n_patch):\n",
    "\n",
    "\tlist_IDs = os.listdir(filename + dataset)\n",
    "\t# choose random instances\n",
    "\tindexes = randint(0, len(list_IDs), n_samples)\n",
    "\tlist_IDs_temp = [list_IDs[k] for k in indexes]\n",
    "\t# retrieve selected images\n",
    "\tX = load_real_samples(dataset, list_IDs_temp, filename, patch_size)\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, n_patch, n_patch, 1))\n",
    "\n",
    "\treturn X, y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(dataset)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# save the generator models to file\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "\t# path to save models\n",
    "\tpath_models = './Models_CycleGAN/'\n",
    "\tif os.path.exists(path_models)==False:\n",
    "\t\tos.mkdir(path_models)\n",
    "\t# save the first generator model\n",
    "\tfilename1 = path_models + 'g_model_AtoB_%03d.h5' % (step+1)\n",
    "\tg_model_AtoB.save(filename1)\n",
    "\t# save the second generator model\n",
    "\tfilename2 = path_models + 'g_model_BtoA_%03d.h5' % (step+1)\n",
    "\tg_model_BtoA.save(filename2)\n",
    "\tprint('>Saved: %s and %s \\n' % (filename1, filename2))\n",
    " \n",
    "\n",
    "def thresholding(patch_prediction):\n",
    "    patch_ind_nuclei = np.argwhere(patch_prediction[:,:,:,0] > 0.5)\n",
    "    #patch_ind_golgi = np.argwhere(patch_prediction[:,:,:,1] > 0.5)\n",
    "\n",
    "    patch_prediction_thr = np.zeros((patch_prediction.shape[0],patch_prediction.shape[1],patch_prediction.shape[2],3))\n",
    "\n",
    "    for i in range(patch_ind_nuclei.shape[0]):\n",
    "      patch_prediction_thr[patch_ind_nuclei[i,0],patch_ind_nuclei[i,1],patch_ind_nuclei[i,2],0]=1 \n",
    "\n",
    "    #for j in range(patch_ind_golgi.shape[0]):\n",
    "    #  patch_prediction_thr[patch_ind_golgi[j,0],patch_ind_golgi[j,1],patch_ind_golgi[j,2],1]=1\n",
    "\n",
    "    return patch_prediction_thr\n",
    "\n",
    "def padding(image,size):\n",
    "\n",
    "    img_reshape = np.moveaxis(image, -1, 0)\n",
    "    \n",
    "    m = ReflectionPad3d((0,size[2]-image.shape[2],0,size[1]-image.shape[1],0,size[0]-image.shape[0]))\n",
    "    _input = torch.tensor(img_reshape, dtype=torch.float)\n",
    "    output = m(_input)\n",
    "    pad_img = output.numpy()\n",
    "    pad_img = np.moveaxis(pad_img, 0, -1)\n",
    "    \n",
    "    return pad_img\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, dataset, name, patch_size, results_path, n_samples=5, filename= './Dataset/Patches_synthetic/Train'):\n",
    "\t# select a sample of input images\n",
    "\tX_in, _ = generate_real_samples(dataset, n_samples, patch_size, filename, 0)\n",
    "\t# generate translated images\n",
    "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "\tX_in = (X_in + 1) / 2.0\n",
    "\tX_out = (X_out + 1) / 2.0\n",
    "\ta = np.zeros((n_samples, *(128,128,64,3)))\n",
    "\tfor i in range(n_samples):\n",
    "\t\t\ta[i,:,:,:,0] = X_in[i]\n",
    "\tX_in = a\n",
    "\n",
    "\tif dataset == '/Masks/':\n",
    "\t\ta = np.zeros((n_samples, *(128,128,64,3)))\n",
    "\t\tfor i in range(n_samples):\n",
    "\t\t\t\ta[i,:,:,:,0] = X_out[i,:,:,:,0]\n",
    "\t\tX_out = a\n",
    "\t# If its a segmentation mask we have to turn to RGB\n",
    "\tif dataset == '/Images/':\n",
    "\t\ta = np.empty((n_samples, *(128,128,64,3)))\n",
    "\t\tfor i in range(n_samples):\n",
    "\t\t\ta[i] = thresholding(X_out[i])\n",
    "\t\tX_out = a\n",
    "\n",
    "\t# plot real images\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.subplot(2, n_samples, 1 + i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_in[i,:,:,25,:])\n",
    "\t# plot translated image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_out[i,:,:,25,:])\n",
    "\t# save plot to file\n",
    "\tfilename1 = results_path + '%s_generated_plot_%06d.png' % (name, (step+1))\n",
    "\tpyplot.savefig(filename1)\n",
    "\tpyplot.close()\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, y_true.dtype)\n",
    "\n",
    "    num = tf.math.reduce_sum(tf.math.multiply(y_true, y_pred))\n",
    "    den = tf.math.reduce_sum(tf.math.add(y_true, y_pred))+1e-5\n",
    "\n",
    "    return 1-2*num/den\n",
    "\n",
    "def compute_dice_coefficient(g_model, dataset, filename, patch_size, n_samples=10):\n",
    "    list_IDs = os.listdir(filename + dataset)\n",
    "    # choose random instances\n",
    "    indexes = randint(0, len(list_IDs), n_samples)\n",
    "    list_IDs_temp = [list_IDs[k] for k in indexes]\n",
    "    # retrieve selected images\n",
    "    X = load_real_samples(dataset, list_IDs_temp, filename, patch_size)\n",
    "    X_out, _ = generate_fake_samples(g_model, X, 0)\n",
    "    \n",
    "    X = (X + 1) / 2.0\n",
    "    X_out = (X_out + 1) / 2.0\n",
    "    \n",
    "    dice_coef = np.empty(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        dice_coef[i] = dice_coefficient(X[i], X_out[i])\n",
    "\n",
    "    print('\\n Dice Loss: {:.4f} \\n'.format(np.mean(dice_coef)))\n",
    "\n",
    "# update image pool for fake images\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "\tselected = list()\n",
    "\tfor image in images:\n",
    "\t\tif len(pool) < max_size:\n",
    "\t\t\t# stock the pool\n",
    "\t\t\tpool.append(image)\n",
    "\t\t\tselected.append(image)\n",
    "\t\telif random() < 0.5:\n",
    "\t\t\t# use image, but don't add it to the pool\n",
    "\t\t\tselected.append(image)\n",
    "\t\telse:\n",
    "\t\t\t# replace an existing image and use replaced image\n",
    "\t\t\tix = randint(0, len(pool))\n",
    "\t\t\tselected.append(pool[ix])\n",
    "\t\t\tpool[ix] = image\n",
    "\treturn asarray(selected)\n",
    "\n",
    "# train cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, filename, img_dim):\n",
    "    # Results\n",
    "    path = './Dataset/Results_CycleGAN/'\n",
    "    if os.path.exists(path)==False:\n",
    "        os.mkdir(path)\n",
    "    # define properties of the training run\n",
    "    n_epochs, n_batch = 100, 1\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    # unpack dataset\n",
    "    list_IDs = os.listdir(filename + '/Images/')\n",
    "    # prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(list_IDs) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    e = 1\n",
    "    steps = 1\n",
    "    print('Epoch {}/{}'.format(e,n_epochs))\n",
    "    prev_g_loss1 = np.inf\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "\t\t# select a batch of real samples\n",
    "        X_realA, y_realA = generate_real_samples('/Images/', n_batch, img_dim, filename, n_patch)\n",
    "        X_realB, y_realB = generate_real_samples('/Masks/', n_batch, img_dim, filename, n_patch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "        # update fakes from pool\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        # update generator B->A via adversarial and cycle loss\n",
    "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        # update discriminator for A -> [real/fake]\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        # update generator A->B via adversarial and cycle loss\n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        # update discriminator for B -> [real/fake]\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        # summarize performance\n",
    "        # print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        stdout.write('\\rBatch: {}/{} - dA[{:.4f},{:.4f}] - dB[{:.4f},{:.4f}] - g[{:.4f},{:.4f}]         '\n",
    "                      .format(steps, bat_per_epo, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        stdout.flush()\n",
    "        steps = steps + 1\n",
    "        \n",
    "        # evaluate the model performance every epoch and save the model if its better\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "\n",
    "            #if g_loss1 < prev_g_loss1:\n",
    "            # save the models\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA)\n",
    "            #prev_g_loss1 = g_loss1\n",
    "\n",
    "            # plot A->B translation\n",
    "            summarize_performance(i, g_model_AtoB, '/Images/', 'AtoB', img_dim, path)\n",
    "            # plot B->A translation\n",
    "            summarize_performance(i, g_model_BtoA, '/Masks/', 'BtoA', img_dim, path)\n",
    "            # compute dice coefficient\n",
    "            # compute_dice_coefficient(g_model_AtoB, '/Images/',filename, img_dim)\n",
    "            \n",
    "            steps = 1\n",
    "            e = e + 1\n",
    "            print('\\n Epoch {}/{} \\n'.format(e,n_epochs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP0hB5gy5RA3",
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10013,
     "status": "ok",
     "timestamp": 1655633630439,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "_VotxHp65QJ_",
    "outputId": "5594477f-8668-44bd-cd0b-d0b69c866d6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 20:26:00.366630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.379328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.379700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.380634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-01 20:26:00.381034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.381352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.381667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.773883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.774044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.774164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-01 20:26:00.774265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7138 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "img_shape = (128,128,64,1)\n",
    "filename = './Dataset/Patches_synthetic/Train'\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(img_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(img_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(img_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(img_shape)\n",
    "\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, img_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fD6EpuDUTirj",
    "outputId": "319653ff-6c72-4838-f9ab-913bc57d1871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 20:26:04.503053: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-10-01 20:26:05.334652: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2022-10-01 20:26:05.505365: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-01 20:26:05.505655: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-01 20:26:05.505697: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-10-01 20:26:05.506099: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-01 20:26:05.506151: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 335/335 - dA[0.0049,0.1558] - dB[0.0092,0.0279] - g[43.9408,44.0865]               >Saved: ./Models_CycleGAN/g_model_AtoB_335.h5 and ./Models_CycleGAN/g_model_BtoA_335.h5 \n",
      "\n",
      "\n",
      " Epoch 2/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0090,0.0052] - dB[0.0142,0.0065] - g[35.1645,35.3572]         >Saved: ./Models_CycleGAN/g_model_AtoB_670.h5 and ./Models_CycleGAN/g_model_BtoA_670.h5 \n",
      "\n",
      "\n",
      " Epoch 3/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0096,0.0770] - dB[0.5320,0.1950] - g[30.9287,29.6406]         >Saved: ./Models_CycleGAN/g_model_AtoB_1005.h5 and ./Models_CycleGAN/g_model_BtoA_1005.h5 \n",
      "\n",
      "\n",
      " Epoch 4/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0653,0.0413] - dB[0.0221,0.0705] - g[23.9739,24.4141]         >Saved: ./Models_CycleGAN/g_model_AtoB_1340.h5 and ./Models_CycleGAN/g_model_BtoA_1340.h5 \n",
      "\n",
      "\n",
      " Epoch 5/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1264,0.0376] - dB[0.0131,0.0023] - g[19.5360,19.8405]         >Saved: ./Models_CycleGAN/g_model_AtoB_1675.h5 and ./Models_CycleGAN/g_model_BtoA_1675.h5 \n",
      "\n",
      "\n",
      " Epoch 6/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0014,0.0030] - dB[0.0008,0.0029] - g[16.5331,16.9026]         >Saved: ./Models_CycleGAN/g_model_AtoB_2010.h5 and ./Models_CycleGAN/g_model_BtoA_2010.h5 \n",
      "\n",
      "\n",
      " Epoch 7/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0534,0.0048] - dB[0.0145,0.0117] - g[13.9280,14.5425]         >Saved: ./Models_CycleGAN/g_model_AtoB_2345.h5 and ./Models_CycleGAN/g_model_BtoA_2345.h5 \n",
      "\n",
      "\n",
      " Epoch 8/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0016,0.0022] - dB[0.0015,0.0077] - g[13.1128,13.0117]         >Saved: ./Models_CycleGAN/g_model_AtoB_2680.h5 and ./Models_CycleGAN/g_model_BtoA_2680.h5 \n",
      "\n",
      "\n",
      " Epoch 9/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0415,0.0064] - dB[0.0069,0.0021] - g[10.3237,10.5200]         >Saved: ./Models_CycleGAN/g_model_AtoB_3015.h5 and ./Models_CycleGAN/g_model_BtoA_3015.h5 \n",
      "\n",
      "\n",
      " Epoch 10/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1536,0.1492] - dB[0.0016,0.0054] - g[8.5593,7.9738]           >Saved: ./Models_CycleGAN/g_model_AtoB_3350.h5 and ./Models_CycleGAN/g_model_BtoA_3350.h5 \n",
      "\n",
      "\n",
      " Epoch 11/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1401,0.1359] - dB[0.5283,0.0157] - g[7.9049,6.9081]         >Saved: ./Models_CycleGAN/g_model_AtoB_3685.h5 and ./Models_CycleGAN/g_model_BtoA_3685.h5 \n",
      "\n",
      "\n",
      " Epoch 12/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0871,0.2296] - dB[0.3882,0.1334] - g[6.1470,6.0763]          >Saved: ./Models_CycleGAN/g_model_AtoB_4020.h5 and ./Models_CycleGAN/g_model_BtoA_4020.h5 \n",
      "\n",
      "\n",
      " Epoch 13/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0221,0.0029] - dB[0.1201,0.2233] - g[5.7811,5.5552]         >Saved: ./Models_CycleGAN/g_model_AtoB_4355.h5 and ./Models_CycleGAN/g_model_BtoA_4355.h5 \n",
      "\n",
      "\n",
      " Epoch 14/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1454,0.1422] - dB[0.0496,0.0395] - g[4.5721,4.4416]           >Saved: ./Models_CycleGAN/g_model_AtoB_4690.h5 and ./Models_CycleGAN/g_model_BtoA_4690.h5 \n",
      "\n",
      "\n",
      " Epoch 15/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1458,0.0073] - dB[0.0586,0.0751] - g[4.1317,4.3939]          >Saved: ./Models_CycleGAN/g_model_AtoB_5025.h5 and ./Models_CycleGAN/g_model_BtoA_5025.h5 \n",
      "\n",
      "\n",
      " Epoch 16/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0198,0.0099] - dB[0.0896,0.0822] - g[4.2963,4.6048]         >Saved: ./Models_CycleGAN/g_model_AtoB_5360.h5 and ./Models_CycleGAN/g_model_BtoA_5360.h5 \n",
      "\n",
      "\n",
      " Epoch 17/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.1017,0.0192] - dB[0.1717,0.1868] - g[3.1833,3.6476]         >Saved: ./Models_CycleGAN/g_model_AtoB_5695.h5 and ./Models_CycleGAN/g_model_BtoA_5695.h5 \n",
      "\n",
      "\n",
      " Epoch 18/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0220,0.1775] - dB[0.2162,0.1912] - g[3.1539,3.0602]         >Saved: ./Models_CycleGAN/g_model_AtoB_6030.h5 and ./Models_CycleGAN/g_model_BtoA_6030.h5 \n",
      "\n",
      "\n",
      " Epoch 19/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0734,0.0600] - dB[0.2288,0.1625] - g[3.2318,3.6672]         >Saved: ./Models_CycleGAN/g_model_AtoB_6365.h5 and ./Models_CycleGAN/g_model_BtoA_6365.h5 \n",
      "\n",
      "\n",
      " Epoch 20/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.0078,0.1021] - dB[0.0130,0.0012] - g[3.7037,3.3854]         >Saved: ./Models_CycleGAN/g_model_AtoB_6700.h5 and ./Models_CycleGAN/g_model_BtoA_6700.h5 \n",
      "\n",
      "\n",
      " Epoch 21/100 \n",
      "\n",
      "Batch: 335/335 - dA[0.2295,0.1184] - dB[0.0276,0.0034] - g[2.9997,3.1471]         >Saved: ./Models_CycleGAN/g_model_AtoB_7035.h5 and ./Models_CycleGAN/g_model_BtoA_7035.h5 \n",
      "\n",
      "\n",
      " Epoch 22/100 \n",
      "\n",
      "Batch: 133/335 - dA[0.1347,0.1301] - dB[0.0065,0.0012] - g[3.1009,2.4456]         "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train models\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_model_AtoB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_model_BtoA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_model_AtoB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_model_BtoA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, filename, img_dim)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# generate a batch of fake samples\u001b[39;00m\n\u001b[1;32m    196\u001b[0m X_fakeA, y_fakeA \u001b[38;5;241m=\u001b[39m generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n\u001b[0;32m--> 197\u001b[0m X_fakeB, y_fakeB \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_fake_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model_AtoB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_realA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_patch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# update fakes from pool\u001b[39;00m\n\u001b[1;32m    199\u001b[0m X_fakeA \u001b[38;5;241m=\u001b[39m update_image_pool(poolA, X_fakeA)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(g_model, dataset, patch_shape)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_fake_samples\u001b[39m(g_model, dataset, patch_shape):\n\u001b[1;32m     34\u001b[0m \t\u001b[38;5;66;03m# generate fake instance\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \tX \u001b[38;5;241m=\u001b[39m \u001b[43mg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \t\u001b[38;5;66;03m# create 'fake' class labels (0)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \ty \u001b[38;5;241m=\u001b[39m zeros((\u001b[38;5;28mlen\u001b[39m(X), patch_shape, patch_shape, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1747\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[1;32m   1746\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py:1180\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1180\u001b[0m   data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:411\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    410\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__() is only supported inside of tf.function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    695\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:719\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[1;32m    715\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    716\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v2(\n\u001b[1;32m    717\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    718\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m   \u001b[38;5;66;03m# Delete the resource when this object is deleted\u001b[39;00m\n\u001b[1;32m    721\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_deleter \u001b[38;5;241m=\u001b[39m IteratorResourceDeleter(\n\u001b[1;32m    722\u001b[0m       handle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[1;32m    723\u001b[0m       deleter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3120\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3119\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3120\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3123\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, filename, img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S4NZZ5bwYtQ",
    "tags": []
   },
   "source": [
    "# Test Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1655719013519,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "M78fwNkKwh4S"
   },
   "outputs": [],
   "source": [
    "def padding(image,size):\n",
    "\n",
    "    img_reshape = np.moveaxis(image, -1, 0)\n",
    "    \n",
    "    m = ReflectionPad3d((0,size[2]-image.shape[2],0,size[1]-image.shape[1],0,size[0]-image.shape[0]))\n",
    "    input = torch.tensor(img_reshape, dtype=torch.float)\n",
    "    output = m(input)\n",
    "    pad_img = output.numpy()\n",
    "    pad_img = np.moveaxis(pad_img, 0, -1)\n",
    "    \n",
    "    return pad_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1655719013828,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "E_EdHMzzwkEp"
   },
   "outputs": [],
   "source": [
    "def thresholding(patch_prediction):\n",
    "    patch_ind_nuclei = np.argwhere(patch_prediction[:,:,:,0] > 0.5)\n",
    "    #patch_ind_golgi = np.argwhere(patch_prediction[:,:,:,1] > 0.5)\n",
    "\n",
    "    patch_prediction_thr = np.zeros((patch_prediction.shape[0],patch_prediction.shape[1],patch_prediction.shape[2],3))\n",
    "    #patch_prediction_thr_final = np.zeros((patch_prediction.shape[0],patch_prediction.shape[1],patch_prediction.shape[2],3))\n",
    "\n",
    "    for i in range(patch_ind_nuclei.shape[0]):\n",
    "        patch_prediction_thr[patch_ind_nuclei[i,0],patch_ind_nuclei[i,1],patch_ind_nuclei[i,2],0]=1 \n",
    "\n",
    "    #for j in range(patch_ind_golgi.shape[0]):\n",
    "    #    patch_prediction_thr[patch_ind_golgi[j,0],patch_ind_golgi[j,1],patch_ind_golgi[j,2],1]=1\n",
    "    \n",
    "    #patch_prediction_thr_final[10:patch_prediction.shape[0]-10, 10:patch_prediction.shape[1]-10, 10:patch_prediction.shape[2]-10, :] = patch_prediction_thr[10:patch_prediction.shape[0]-10, 10:patch_prediction.shape[1]-10, 10:patch_prediction.shape[2]-10, :]\n",
    "\n",
    "    \n",
    "    return patch_prediction_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1655719013829,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "kFSYuLBPwmBc"
   },
   "outputs": [],
   "source": [
    "def pred_mask(image, mask_shape):\n",
    "    patch_size = 128\n",
    "    step = 64\n",
    "\n",
    "    pred_mask = np.zeros(((image.shape[0] // step)*step + patch_size,(image.shape[1] // step)*step + patch_size,64,3))\n",
    "    _image = (padding(image, ((image.shape[0] // step)*step + patch_size,(image.shape[1] // step)*step + patch_size,64,3)))[:,:,:,0]\n",
    "\n",
    "    i = 0\n",
    "    while i + patch_size <= _image.shape[0]:\n",
    "        j = 0\n",
    "        while j + patch_size <= _image.shape[1]:\n",
    "\n",
    "            tst_patch = _image[i:i+patch_size, j:j+patch_size, :]\n",
    "            tst_patch = np.array([(tst_patch - 127.5) / 127.5])\n",
    "            preds_tst = my_model.predict(tst_patch)\n",
    "            preds_tst = (preds_tst + 1) / 2.0\n",
    "            pred_patch = preds_tst[0,:,:,:,:]\n",
    "            pred_patch_thr = thresholding(pred_patch)\n",
    "\n",
    "            pred_mask[i:i+patch_size, j:j+patch_size,:,0] = np.array(np.logical_or(pred_mask[i:i+patch_size, j:j+patch_size, :,0], pred_patch_thr[:,:,:,0], dtype = 'float64'))\n",
    "            #pred_mask[i:i+patch_size, j:j+patch_size,:,1] = 0\n",
    "            #pred_mask[i:i+patch_size, j:j+patch_size,:,2] = 0\n",
    "\n",
    "            j += step\n",
    "\n",
    "        i += step\n",
    "\n",
    "    _pred_mask = np.zeros(mask_shape)\n",
    "    _pred_mask = pred_mask[0:mask_shape[0],0:mask_shape[1],0:mask_shape[2],:]\n",
    "\n",
    "    return _pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1655719014087,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "_Ny5V_2WwoJ6"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smoothing_factor = 1\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return(K.sum(flat_y_true * flat_y_pred) / K.sum(flat_y_pred) )\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    flat_y_true = K.flatten(y_true)\n",
    "    flat_y_pred = K.flatten(y_pred)\n",
    "    return(K.sum(flat_y_true * flat_y_pred) / K.sum(flat_y_true) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1655719014089,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "JkqIRTBAwp47"
   },
   "outputs": [],
   "source": [
    "def metrics(mask, _pred_mask):\n",
    "    _mask = mask/255.\n",
    "\n",
    "    dice_coef_nuclei = dice_coefficient(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "    dice_coef_golgi = dice_coefficient(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "    prec_nuclei = precision(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "    prec_golgi = precision(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "    recall_nuclei = recall(_mask[:,:,:,1],_pred_mask[:,:,:,1])\n",
    "    recall_golgi = recall(_mask[:,:,:,0],_pred_mask[:,:,:,0])\n",
    "\n",
    "    return [round(dice_coef_nuclei.numpy(),4), round(dice_coef_golgi.numpy(),4), \n",
    "          round(prec_nuclei.numpy(),4), round(prec_golgi.numpy(),4), round(recall_nuclei.numpy(),4),\n",
    "          round(recall_golgi.numpy(),4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1655719014090,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "opglOpuzwsIm"
   },
   "outputs": [],
   "source": [
    "def write_to_excel(wb,sheet_name,metrics, result_dir):\n",
    "\n",
    "    # add_sheet is used to create sheet.\n",
    "    sheet1 = wb.add_sheet(sheet_name)\n",
    "\n",
    "    sheet1.write(0, 0, 'Dice Coeffient Nuclei')\n",
    "    sheet1.write(0, 1, 'Dice Coeffient Golgi')\n",
    "    sheet1.write(0, 2, 'Precision Nuclei')\n",
    "    sheet1.write(0, 3, 'Precision Golgi')\n",
    "    sheet1.write(0, 4, 'Recall Nuclei')\n",
    "    sheet1.write(0, 5, 'Recall Golgi')\n",
    "    sheet1.write(1, 0, metrics[0])\n",
    "    sheet1.write(1, 1, metrics[1])\n",
    "    sheet1.write(1, 2, metrics[2])\n",
    "    sheet1.write(1, 3, metrics[3])\n",
    "    sheet1.write(1, 4, metrics[4])\n",
    "    sheet1.write(1, 5, metrics[5])\n",
    "\n",
    "    wb.save(result_dir + '/results_metrics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1655719014090,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "8yDXNAWGwviV"
   },
   "outputs": [],
   "source": [
    "def test_model(base_dir):\n",
    "\n",
    "    fnames = os.listdir(base_dir + 'Images/')\n",
    "\n",
    "    # Workbook is created\n",
    "    wb = Workbook()\n",
    "\n",
    "    result_dir = './Dataset/Results_CycleGAN'\n",
    "    if os.path.exists(result_dir)==False:\n",
    "        os.mkdir(result_dir)\n",
    "\n",
    "    for i in range(len(fnames)):\n",
    "\n",
    "        image = imread(base_dir + 'Images/' + fnames[i])\n",
    "        mask = imread(base_dir + 'Masks/' + fnames[i])\n",
    "\n",
    "        predicted_mask = pred_mask(image, image.shape)\n",
    "\n",
    "        _predicted_mask = predicted_mask*255.0\n",
    "        _predicted_mask = _predicted_mask.astype('uint8')\n",
    "\n",
    "        imwrite(result_dir + '/pred_mask_' + fnames[i] , _predicted_mask, photometric='rgb')\n",
    "\n",
    "        _metrics = metrics(mask, predicted_mask)\n",
    "\n",
    "        write_to_excel(wb,'Sheet_' + fnames[i].split('.')[0], _metrics, result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136212,
     "status": "ok",
     "timestamp": 1655719184999,
     "user": {
      "displayName": "Alice Henriques da Rosa",
      "userId": "12243278505695630565"
     },
     "user_tz": -60
    },
    "id": "8Uk3-amtwwMW",
    "outputId": "635ef0c8-f8e9-46db-a347-cbf291a61844"
   },
   "outputs": [],
   "source": [
    "#Load the pretrained model for testing and predictions. \n",
    "\n",
    "#Load the pretrained model for testing and predictions. \n",
    "from keras.models import load_model\n",
    "my_model = load_model('./Models_CycleGAN/g_model_AtoB_3350.h5', compile=False, custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "#If you load a different model do not forget to preprocess accordingly. \n",
    "\n",
    "base_dir = './Dataset/Patches_synthetic/Test/'\n",
    "\n",
    "test_model(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgOh29oJMzW3",
    "tags": []
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(filename, dataset):\n",
    "    \n",
    "    list_IDs = os.listdir(filename + dataset)\n",
    "    i = 0\n",
    "\n",
    "    for ID in list_IDs:\n",
    "        X = imread(filename + dataset + ID)[:,:,:,0]\n",
    "        is_all_zeros = np.all((X == 0))\n",
    "        if is_all_zeros:\n",
    "            os.remove(filename + dataset + ID)\n",
    "            os.remove(filename + '/Images/' + ID)\n",
    "            print(\"File\",ID,\"deleted\")\n",
    "            i = i+1\n",
    "    print(len(list_IDs), i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#pre_processing('./Dataset/Patches_Pre/Train', '/Masks/')\n",
    "list_IDs = os.listdir('./Dataset/Patches_Pre/Train' + '/Masks/')\n",
    "print(len(list_IDs))\n",
    "list_IDs_ = os.listdir('./Dataset/Patches_Pre/Train' + '/Images/')\n",
    "print(len(list_IDs_))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNsBO+gt9lsQYL2a5E+6P0i",
   "collapsed_sections": [
    "fgOh29oJMzW3"
   ],
   "name": "CycleGAN_V3.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
